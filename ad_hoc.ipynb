{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,3], [2,4], [3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1,2],[3,1],[4,2],[5,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.23606798, 3.60555128],\n",
       "       [2.82842712, 3.16227766, 4.        ],\n",
       "       [3.16227766, 2.82842712, 3.16227766],\n",
       "       [4.        , 3.16227766, 2.82842712]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.square(a-b[:,None,:]).sum(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.82842712, 3.16227766, 4.        ],\n",
       "       [2.23606798, 3.16227766, 2.82842712, 3.16227766],\n",
       "       [3.60555128, 4.        , 3.16227766, 2.82842712]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sq_sum = np.einsum('ik,ik->i',a,a)\n",
    "\n",
    "b_sq_sum = np.einsum('ik,ik->i',b,b)\n",
    "\n",
    "a_dot_b = a.dot(b.T)\n",
    "\n",
    "np.sqrt(a_sq_sum[:,None]-2*a_dot_b+b_sq_sum[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_sq_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 1],\n",
       "       [4, 2],\n",
       "       [5, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  6],\n",
       "        [ 3,  3],\n",
       "        [ 4,  6],\n",
       "        [ 5,  9]],\n",
       "\n",
       "       [[ 2,  8],\n",
       "        [ 6,  4],\n",
       "        [ 8,  8],\n",
       "        [10, 12]],\n",
       "\n",
       "       [[ 3, 10],\n",
       "        [ 9,  5],\n",
       "        [12, 10],\n",
       "        [15, 15]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ik,jk->ijk', a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [Emma, F, 20799]\n",
       "1           [Olivia, F, 19674]\n",
       "2           [Sophia, F, 18490]\n",
       "3         [Isabella, F, 16950]\n",
       "4              [Ava, F, 15586]\n",
       "5              [Mia, F, 13442]\n",
       "6            [Emily, F, 12562]\n",
       "7          [Abigail, F, 11985]\n",
       "8          [Madison, F, 10247]\n",
       "9        [Charlotte, F, 10048]\n",
       "10           [Harper, F, 9564]\n",
       "11            [Sofia, F, 9542]\n",
       "12            [Avery, F, 9517]\n",
       "13        [Elizabeth, F, 9492]\n",
       "14           [Amelia, F, 8727]\n",
       "15           [Evelyn, F, 8692]\n",
       "16             [Ella, F, 8489]\n",
       "17            [Chloe, F, 8469]\n",
       "18         [Victoria, F, 7955]\n",
       "19           [Aubrey, F, 7589]\n",
       "20            [Grace, F, 7554]\n",
       "21             [Zoey, F, 7358]\n",
       "22          [Natalie, F, 7061]\n",
       "23          [Addison, F, 6950]\n",
       "24          [Lillian, F, 6869]\n",
       "25         [Brooklyn, F, 6767]\n",
       "26             [Lily, F, 6727]\n",
       "27           [Hannah, F, 6512]\n",
       "28            [Layla, F, 6428]\n",
       "29         [Scarlett, F, 5965]\n",
       "                 ...          \n",
       "33014          [Zedrick, M, 5]\n",
       "33015             [Zeid, M, 5]\n",
       "33016           [Zeidan, M, 5]\n",
       "33017         [Zekeriah, M, 5]\n",
       "33018            [Zenas, M, 5]\n",
       "33019           [Zephen, M, 5]\n",
       "33020           [Zerick, M, 5]\n",
       "33021          [Zhaiden, M, 5]\n",
       "33022           [Zhalen, M, 5]\n",
       "33023          [Zhayden, M, 5]\n",
       "33024             [Ziar, M, 5]\n",
       "33025           [Zichen, M, 5]\n",
       "33026            [Ziden, M, 5]\n",
       "33027           [Zierre, M, 5]\n",
       "33028            [Ziion, M, 5]\n",
       "33029            [Zijun, M, 5]\n",
       "33030            [Zilas, M, 5]\n",
       "33031            [Zirui, M, 5]\n",
       "33032            [Zivon, M, 5]\n",
       "33033            [Ziyah, M, 5]\n",
       "33034           [Ziyang, M, 5]\n",
       "33035          [Zmarion, M, 5]\n",
       "33036               [Zo, M, 5]\n",
       "33037            [Zyeir, M, 5]\n",
       "33038             [Zyel, M, 5]\n",
       "33039           [Zykeem, M, 5]\n",
       "33040           [Zymeer, M, 5]\n",
       "33041          [Zymiere, M, 5]\n",
       "33042            [Zyran, M, 5]\n",
       "33043            [Zyrin, M, 5]\n",
       "Name: name, Length: 33044, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data I/O\n",
    "data = open('input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print 'data has %d characters, %d unique.' % (data_size, vocab_size)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('./data/names.csv', 'r').read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.from_numpy(X).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt = torch.from_numpy(W).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.requires_grad=True\n",
    "Wt.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.mm(Xt,Wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9203,  1.5850],\n",
       "        [ 0.9203,  1.5850],\n",
       "        [ 0.9203,  1.5850]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt.grad_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x70f1050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 53)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1473,  0.4982,  0.2940]]),\n",
       " tensor([[-0.6479, -0.3016,  0.8846]]),\n",
       " tensor([[-2.1708,  1.4156, -1.2350]]),\n",
       " tensor([[ 0.4750,  1.0067,  1.1034]]),\n",
       " tensor([[ 1.8504, -1.1481, -0.9657]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 53),\n",
    "          torch.randn(1, 1, 53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0108,  0.9641, -0.0155, -0.4458,  0.6492,  1.0110, -0.1790,\n",
       "            1.1213, -1.1228,  1.8543,  2.1210, -0.0820,  0.6591, -0.5572,\n",
       "            0.8680, -0.0472, -1.0035,  1.1797,  1.0145, -0.2112, -0.9302,\n",
       "           -1.6994, -0.3377,  1.0027, -0.5757,  3.1404, -0.0570, -0.6788,\n",
       "            1.4388,  0.9930, -0.1493,  0.2475, -0.2305, -1.6334, -1.3680,\n",
       "            1.8830,  0.7859, -1.2736,  0.1215, -0.8529, -0.2263,  1.5190,\n",
       "           -0.8346,  0.6603, -0.0719,  0.5490, -1.3864,  1.4419,  2.0726,\n",
       "           -0.6147,  1.8651,  0.5468,  1.7908]]]),\n",
       " tensor([[[ 1.1290,  0.6676,  1.5335, -1.7290,  1.3343,  0.3848, -0.4191,\n",
       "           -0.4365,  0.1525, -1.9404,  0.8214, -0.4543, -0.8003,  1.0910,\n",
       "            0.2255,  0.7864, -1.8711, -0.9593, -1.0922, -1.0436, -0.6740,\n",
       "            1.0460, -0.8622, -0.4517,  0.6310, -1.6984, -0.3481, -0.0629,\n",
       "            1.1751, -0.0493, -0.2135, -0.0925,  0.7878, -0.8293, -1.3540,\n",
       "            0.7667, -0.6760,  1.1454, -0.4260, -1.4792, -0.8347, -0.1957,\n",
       "            1.1215, -1.9472, -3.4348, -0.2004, -1.2838, -1.8027, -0.7367,\n",
       "            0.8207, -0.2209, -0.4715,  0.1971]]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1473,  0.4982,  0.2940]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.view(1, 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0108,  0.9641, -0.0155, -0.4458,  0.6492,  1.0110, -0.1790,\n",
       "            1.1213, -1.1228,  1.8543,  2.1210, -0.0820,  0.6591, -0.5572,\n",
       "            0.8680, -0.0472, -1.0035,  1.1797,  1.0145, -0.2112, -0.9302,\n",
       "           -1.6994, -0.3377,  1.0027, -0.5757,  3.1404, -0.0570, -0.6788,\n",
       "            1.4388,  0.9930, -0.1493,  0.2475, -0.2305, -1.6334, -1.3680,\n",
       "            1.8830,  0.7859, -1.2736,  0.1215, -0.8529, -0.2263,  1.5190,\n",
       "           -0.8346,  0.6603, -0.0719,  0.5490, -1.3864,  1.4419,  2.0726,\n",
       "           -0.6147,  1.8651,  0.5468,  1.7908]]]),\n",
       " tensor([[[ 1.1290,  0.6676,  1.5335, -1.7290,  1.3343,  0.3848, -0.4191,\n",
       "           -0.4365,  0.1525, -1.9404,  0.8214, -0.4543, -0.8003,  1.0910,\n",
       "            0.2255,  0.7864, -1.8711, -0.9593, -1.0922, -1.0436, -0.6740,\n",
       "            1.0460, -0.8622, -0.4517,  0.6310, -1.6984, -0.3481, -0.0629,\n",
       "            1.1751, -0.0493, -0.2135, -0.0925,  0.7878, -0.8293, -1.3540,\n",
       "            0.7667, -0.6760,  1.1454, -0.4260, -1.4792, -0.8347, -0.1957,\n",
       "            1.1215, -1.9472, -3.4348, -0.2004, -1.2838, -1.8027, -0.7367,\n",
       "            0.8207, -0.2209, -0.4715,  0.1971]]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3673,  0.1974,  0.3867, -0.1894,  0.1782,  0.0776, -0.1106,\n",
       "          -0.0759,  0.0917, -0.2860,  0.2346,  0.3398, -0.0859, -0.0009,\n",
       "          -0.1181,  0.2300, -0.3513, -0.1808, -0.0921, -0.2064, -0.0829,\n",
       "           0.4640, -0.0947, -0.1406,  0.2815, -0.4392, -0.0492,  0.0915,\n",
       "           0.3358,  0.0783, -0.0563, -0.0147,  0.4419, -0.1707, -0.5098,\n",
       "           0.0686,  0.0099,  0.3897, -0.2950, -0.4322, -0.4559, -0.2449,\n",
       "           0.0961, -0.4307, -0.3366, -0.1852, -0.1735, -0.1075,  0.1531,\n",
       "           0.0271,  0.0627, -0.2219,  0.0221]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3673,  0.1974,  0.3867, -0.1894,  0.1782,  0.0776, -0.1106,\n",
       "           -0.0759,  0.0917, -0.2860,  0.2346,  0.3398, -0.0859, -0.0009,\n",
       "           -0.1181,  0.2300, -0.3513, -0.1808, -0.0921, -0.2064, -0.0829,\n",
       "            0.4640, -0.0947, -0.1406,  0.2815, -0.4392, -0.0492,  0.0915,\n",
       "            0.3358,  0.0783, -0.0563, -0.0147,  0.4419, -0.1707, -0.5098,\n",
       "            0.0686,  0.0099,  0.3897, -0.2950, -0.4322, -0.4559, -0.2449,\n",
       "            0.0961, -0.4307, -0.3366, -0.1852, -0.1735, -0.1075,  0.1531,\n",
       "            0.0271,  0.0627, -0.2219,  0.0221]]]),\n",
       " tensor([[[ 0.9025,  0.3281,  0.8705, -0.5258,  0.9366,  0.1402, -0.1928,\n",
       "           -0.2206,  0.2082, -0.7292,  0.2981,  0.5488, -0.1498, -0.0015,\n",
       "           -0.2559,  0.6147, -1.0476, -0.4644, -0.1595, -0.5448, -0.2217,\n",
       "            0.9566, -0.1497, -0.3833,  0.6586, -0.9811, -0.2646,  0.3418,\n",
       "            0.4320,  0.2392, -0.0920, -0.0483,  0.7604, -0.4533, -1.2150,\n",
       "            0.2456,  0.0253,  0.7643, -0.4498, -0.7378, -0.8812, -0.4504,\n",
       "            0.7517, -1.1225, -0.5825, -0.3606, -0.4521, -1.1694,  0.2468,\n",
       "            0.0474,  0.1064, -0.3022,  0.0493]]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
      "\n",
      "        [[-0.3521,  0.1026, -0.2971]],\n",
      "\n",
      "        [[-0.3191,  0.0781, -0.1957]],\n",
      "\n",
      "        [[-0.1634,  0.0941, -0.1637]],\n",
      "\n",
      "        [[-0.3368,  0.0959, -0.0538]]])\n",
      "(tensor([[[-0.3368,  0.0959, -0.0538]]]), tensor([[[-0.9825,  0.4715, -0.0633]]]))\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    " \n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence,self).__init__()\n",
    "        self.lstm1 = nn.LSTM(1,64)\n",
    "        self.lstm2 = nn.LSTM(64,1)\n",
    "        self.p = 0.5\n",
    " \n",
    "    def forward(self,seq, hc = None):\n",
    "        out = []\n",
    "        if hc == None:\n",
    "            hc1, hc2 = None, None\n",
    "        else:\n",
    "            hc1, hc2 = hc\n",
    "        X_in = torch.unsqueeze(seq[0],0)\n",
    "        for X in seq.chunk(seq.size(0),dim=0):\n",
    "            if np.random.rand()>self.p:\n",
    "                X_in = X\n",
    "            tmp, hc1 = self.lstm1(X_in,hc1)\n",
    "            X_in, hc2 = self.lstm2(tmp,hc2)\n",
    "            out.append(X_in)\n",
    "        return torch.stack(out).squeeze(1),(hc1,hc2)\n",
    " \n",
    "# Test\n",
    "lstm = Sequence()\n",
    "X_seq = torch.tensor(np.random.rand(100,1,1), dtype=torch.float)\n",
    "lstm_out = lstm(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[-0.0445,  0.0783, -0.0575,  0.0463,  0.0175,  0.0080,  0.0249,\n",
       "            -0.0785, -0.0307, -0.0762, -0.0609, -0.0316, -0.0110, -0.0410,\n",
       "            -0.0043,  0.0139,  0.0379,  0.0886, -0.0738, -0.0733,  0.0397,\n",
       "            -0.1035,  0.0033,  0.0569, -0.0927,  0.0353, -0.0167,  0.0190,\n",
       "             0.0276,  0.0426, -0.0640,  0.0295, -0.0051, -0.0398, -0.0054,\n",
       "             0.0053, -0.0654, -0.0461,  0.0017,  0.0228, -0.0723, -0.0047,\n",
       "            -0.0415, -0.0012, -0.0235,  0.0422,  0.0709,  0.0471, -0.0242,\n",
       "            -0.0387,  0.0315,  0.1014, -0.0630,  0.0535,  0.0032, -0.0651,\n",
       "             0.1014,  0.0221, -0.0247, -0.0672, -0.0038, -0.0189,  0.0288,\n",
       "             0.0687]]]),\n",
       "  tensor([[[-0.0884,  0.1637, -0.1091,  0.0993,  0.0328,  0.0144,  0.0466,\n",
       "            -0.1557, -0.0654, -0.1720, -0.1278, -0.0574, -0.0223, -0.0781,\n",
       "            -0.0089,  0.0282,  0.0784,  0.1693, -0.1597, -0.1539,  0.0752,\n",
       "            -0.2072,  0.0070,  0.1034, -0.2013,  0.0664, -0.0352,  0.0386,\n",
       "             0.0552,  0.0841, -0.1197,  0.0603, -0.0117, -0.0857, -0.0104,\n",
       "             0.0109, -0.1380, -0.0961,  0.0034,  0.0432, -0.1472, -0.0100,\n",
       "            -0.0862, -0.0024, -0.0442,  0.0884,  0.1421,  0.0959, -0.0489,\n",
       "            -0.0717,  0.0677,  0.1974, -0.1216,  0.1117,  0.0065, -0.1241,\n",
       "             0.2040,  0.0478, -0.0515, -0.1369, -0.0071, -0.0384,  0.0617,\n",
       "             0.1524]]])),\n",
       " (tensor(1.00000e-02 *\n",
       "         [[[ 4.6489]]]), tensor([[[ 0.1888]]])))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-7af4a9e2397a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "torch.Tensor(np.random(100,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.50114598]],\n",
       "\n",
       "       [[0.20965955]],\n",
       "\n",
       "       [[0.80330871]],\n",
       "\n",
       "       [[0.9488637 ]],\n",
       "\n",
       "       [[0.31654119]],\n",
       "\n",
       "       [[0.42908987]],\n",
       "\n",
       "       [[0.76255475]],\n",
       "\n",
       "       [[0.88971279]],\n",
       "\n",
       "       [[0.2236121 ]],\n",
       "\n",
       "       [[0.41544046]],\n",
       "\n",
       "       [[0.08176812]],\n",
       "\n",
       "       [[0.96080615]],\n",
       "\n",
       "       [[0.07837588]],\n",
       "\n",
       "       [[0.7813583 ]],\n",
       "\n",
       "       [[0.71236155]],\n",
       "\n",
       "       [[0.61929028]],\n",
       "\n",
       "       [[0.87964046]],\n",
       "\n",
       "       [[0.47461922]],\n",
       "\n",
       "       [[0.34759049]],\n",
       "\n",
       "       [[0.1074445 ]],\n",
       "\n",
       "       [[0.2683606 ]],\n",
       "\n",
       "       [[0.46236363]],\n",
       "\n",
       "       [[0.62883829]],\n",
       "\n",
       "       [[0.93127517]],\n",
       "\n",
       "       [[0.03086925]],\n",
       "\n",
       "       [[0.04865487]],\n",
       "\n",
       "       [[0.96027268]],\n",
       "\n",
       "       [[0.69841834]],\n",
       "\n",
       "       [[0.56360569]],\n",
       "\n",
       "       [[0.66332749]],\n",
       "\n",
       "       [[0.7611323 ]],\n",
       "\n",
       "       [[0.42187838]],\n",
       "\n",
       "       [[0.45288885]],\n",
       "\n",
       "       [[0.52606369]],\n",
       "\n",
       "       [[0.08862899]],\n",
       "\n",
       "       [[0.23550386]],\n",
       "\n",
       "       [[0.90156089]],\n",
       "\n",
       "       [[0.55168067]],\n",
       "\n",
       "       [[0.63812317]],\n",
       "\n",
       "       [[0.32692986]],\n",
       "\n",
       "       [[0.83661943]],\n",
       "\n",
       "       [[0.70245984]],\n",
       "\n",
       "       [[0.09447782]],\n",
       "\n",
       "       [[0.2512673 ]],\n",
       "\n",
       "       [[0.53750168]],\n",
       "\n",
       "       [[0.15054504]],\n",
       "\n",
       "       [[0.14295852]],\n",
       "\n",
       "       [[0.83211875]],\n",
       "\n",
       "       [[0.17729094]],\n",
       "\n",
       "       [[0.51594176]],\n",
       "\n",
       "       [[0.73587545]],\n",
       "\n",
       "       [[0.88928274]],\n",
       "\n",
       "       [[0.28282668]],\n",
       "\n",
       "       [[0.30075163]],\n",
       "\n",
       "       [[0.11787909]],\n",
       "\n",
       "       [[0.62265903]],\n",
       "\n",
       "       [[0.55020267]],\n",
       "\n",
       "       [[0.3761519 ]],\n",
       "\n",
       "       [[0.40100053]],\n",
       "\n",
       "       [[0.41720121]],\n",
       "\n",
       "       [[0.64658369]],\n",
       "\n",
       "       [[0.98297064]],\n",
       "\n",
       "       [[0.39365065]],\n",
       "\n",
       "       [[0.99435338]],\n",
       "\n",
       "       [[0.53410856]],\n",
       "\n",
       "       [[0.1085457 ]],\n",
       "\n",
       "       [[0.13181726]],\n",
       "\n",
       "       [[0.06265076]],\n",
       "\n",
       "       [[0.59182702]],\n",
       "\n",
       "       [[0.07740798]],\n",
       "\n",
       "       [[0.96625689]],\n",
       "\n",
       "       [[0.02216745]],\n",
       "\n",
       "       [[0.27421965]],\n",
       "\n",
       "       [[0.35007533]],\n",
       "\n",
       "       [[0.24486857]],\n",
       "\n",
       "       [[0.54576034]],\n",
       "\n",
       "       [[0.84867756]],\n",
       "\n",
       "       [[0.44097077]],\n",
       "\n",
       "       [[0.37097819]],\n",
       "\n",
       "       [[0.03849997]],\n",
       "\n",
       "       [[0.45678536]],\n",
       "\n",
       "       [[0.22038384]],\n",
       "\n",
       "       [[0.03867838]],\n",
       "\n",
       "       [[0.76334982]],\n",
       "\n",
       "       [[0.82658949]],\n",
       "\n",
       "       [[0.00233089]],\n",
       "\n",
       "       [[0.30888262]],\n",
       "\n",
       "       [[0.24296219]],\n",
       "\n",
       "       [[0.38142995]],\n",
       "\n",
       "       [[0.14535869]],\n",
       "\n",
       "       [[0.9905779 ]],\n",
       "\n",
       "       [[0.06622199]],\n",
       "\n",
       "       [[0.23177544]],\n",
       "\n",
       "       [[0.81265554]],\n",
       "\n",
       "       [[0.96634444]],\n",
       "\n",
       "       [[0.69985887]],\n",
       "\n",
       "       [[0.11005451]],\n",
       "\n",
       "       [[0.59687068]],\n",
       "\n",
       "       [[0.29252843]],\n",
       "\n",
       "       [[0.56813414]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(100,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-307d72d4a909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chain' is not defined"
     ]
    }
   ],
   "source": [
    "lstm1 = nn.LSTM(1,64)\n",
    "lstm2 = nn.LSTM(64,1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(chain(lstm1.parameters(),lstm2.parameters()), lr=0.0001)\n",
    "for i in range(500):\n",
    "    data = np.sin(np.linspace(0,5,100)+2*np.pi*np.random.rand())\n",
    "    xs = data[:-1]\n",
    "    ys = data[1:]\n",
    "    X = Variable(torch.Tensor(xs).view(-1,1,1))\n",
    "    y = Variable(torch.Tensor(ys))\n",
    "    lstm1.zero_grad()\n",
    "    lstm2.zero_grad()\n",
    "    lstm_out, _ = lstm1(X,None)\n",
    "    lstm_out, _ = lstm2(lstm_out,None)\n",
    "    loss = criterion(lstm_out,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%10 == 0:\n",
    "        print(\"i {}, loss {}\".format(i,loss.data.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.911747300251674"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
